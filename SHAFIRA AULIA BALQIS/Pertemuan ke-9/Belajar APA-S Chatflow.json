{
  "nodes": [
    {
      "id": "openAI_0",
      "position": {
        "x": -501.1901552142226,
        "y": -112.1480963633342
      },
      "type": "customNode",
      "data": {
        "id": "openAI_0",
        "label": "OpenAI",
        "version": 4,
        "name": "openAI",
        "type": "OpenAI",
        "baseClasses": [
          "OpenAI",
          "BaseLLM",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "LLMs",
        "description": "Wrapper around OpenAI large language models",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "openAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-3.5-turbo-instruct",
            "id": "openAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.7,
            "optional": true,
            "id": "openAI_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-topP-number"
          },
          {
            "label": "Best Of",
            "name": "bestOf",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-bestOf-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-presencePenalty-number"
          },
          {
            "label": "Batch Size",
            "name": "batchSize",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-batchSize-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-basepath-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "openAI_0-input-baseOptions-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "openAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-3.5-turbo-instruct",
          "temperature": 0.7,
          "maxTokens": "",
          "topP": "",
          "bestOf": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "batchSize": "",
          "timeout": "",
          "basepath": "",
          "baseOptions": ""
        },
        "outputAnchors": [
          {
            "id": "openAI_0-output-openAI-OpenAI|BaseLLM|BaseLanguageModel|Runnable",
            "name": "openAI",
            "label": "OpenAI",
            "description": "Wrapper around OpenAI large language models",
            "type": "OpenAI | BaseLLM | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 574,
      "selected": false,
      "positionAbsolute": {
        "x": -501.1901552142226,
        "y": -112.1480963633342
      },
      "dragging": false
    },
    {
      "id": "cohere_0",
      "position": {
        "x": 403.41891090999746,
        "y": -157.87508801893316
      },
      "type": "customNode",
      "data": {
        "id": "cohere_0",
        "label": "Cohere",
        "version": 3,
        "name": "cohere",
        "type": "Cohere",
        "baseClasses": [
          "Cohere",
          "LLM",
          "BaseLLM",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "LLMs",
        "description": "Wrapper around Cohere large language models",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "cohereApi"
            ],
            "id": "cohere_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "command",
            "id": "cohere_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.7,
            "optional": true,
            "id": "cohere_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "id": "cohere_0-input-maxTokens-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "cohere_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "command",
          "temperature": 0.7,
          "maxTokens": ""
        },
        "outputAnchors": [
          {
            "id": "cohere_0-output-cohere-Cohere|LLM|BaseLLM|BaseLanguageModel|Runnable",
            "name": "cohere",
            "label": "Cohere",
            "description": "Wrapper around Cohere large language models",
            "type": "Cohere | LLM | BaseLLM | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 620,
      "positionAbsolute": {
        "x": 403.41891090999746,
        "y": -157.87508801893316
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "azureOpenAI_0",
      "position": {
        "x": 836.5403763699834,
        "y": -126.15659686150994
      },
      "type": "customNode",
      "data": {
        "id": "azureOpenAI_0",
        "label": "Azure OpenAI",
        "version": 4,
        "name": "azureOpenAI",
        "type": "AzureOpenAI",
        "baseClasses": [
          "AzureOpenAI",
          "BaseLLM",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "LLMs",
        "description": "Wrapper around Azure OpenAI large language models",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "azureOpenAIApi"
            ],
            "id": "azureOpenAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "text-davinci-003",
            "id": "azureOpenAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "azureOpenAI_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "azureOpenAI_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "azureOpenAI_0-input-topP-number"
          },
          {
            "label": "Best Of",
            "name": "bestOf",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "azureOpenAI_0-input-bestOf-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "azureOpenAI_0-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "azureOpenAI_0-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "azureOpenAI_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "azureOpenAI_0-input-basepath-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "azureOpenAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "text-davinci-003",
          "temperature": 0.9,
          "maxTokens": "",
          "topP": "",
          "bestOf": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "basepath": ""
        },
        "outputAnchors": [
          {
            "id": "azureOpenAI_0-output-azureOpenAI-AzureOpenAI|BaseLLM|BaseLanguageModel|Runnable",
            "name": "azureOpenAI",
            "label": "AzureOpenAI",
            "description": "Wrapper around Azure OpenAI large language models",
            "type": "AzureOpenAI | BaseLLM | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 574,
      "positionAbsolute": {
        "x": 836.5403763699834,
        "y": -126.15659686150994
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "fireworks_0",
      "position": {
        "x": 1172.3188862089119,
        "y": 13.404764231152186
      },
      "type": "customNode",
      "data": {
        "id": "fireworks_0",
        "label": "Fireworks",
        "version": 1,
        "name": "fireworks",
        "type": "Fireworks",
        "baseClasses": [
          "Fireworks",
          "OpenAI",
          "BaseLLM",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "LLMs",
        "description": "Wrapper around Fireworks API for large language models",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "fireworksApi"
            ],
            "id": "fireworks_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "string",
            "default": "accounts/fireworks/models/llama-v3-70b-instruct-hf",
            "description": "For more details see https://fireworks.ai/models",
            "optional": true,
            "id": "fireworks_0-input-modelName-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "fireworks_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "accounts/fireworks/models/llama-v3-70b-instruct-hf"
        },
        "outputAnchors": [
          {
            "id": "fireworks_0-output-fireworks-Fireworks|OpenAI|BaseLLM|BaseLanguageModel|Runnable",
            "name": "fireworks",
            "label": "Fireworks",
            "description": "Wrapper around Fireworks API for large language models",
            "type": "Fireworks | OpenAI | BaseLLM | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 425,
      "selected": false,
      "positionAbsolute": {
        "x": 1172.3188862089119,
        "y": 13.404764231152186
      },
      "dragging": false
    },
    {
      "id": "GooglePaLM_0",
      "position": {
        "x": -20.952625954836748,
        "y": -138.18774867984288
      },
      "type": "customNode",
      "data": {
        "id": "GooglePaLM_0",
        "label": "GooglePaLM",
        "version": 3,
        "name": "GooglePaLM",
        "type": "GooglePaLM",
        "baseClasses": [
          "GooglePaLM",
          "LLM",
          "BaseLLM",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "LLMs",
        "description": "Wrapper around Google MakerSuite PaLM large language models",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleMakerSuite"
            ],
            "id": "GooglePaLM_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "models/text-bison-001",
            "id": "GooglePaLM_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.7,
            "optional": true,
            "description": "Controls the randomness of the output.\nValues can range from [0.0,1.0], inclusive. A value closer to 1.0 will produce responses that are more varied and creative, while a value closer to 0.0 will typically result in more straightforward responses from the model.",
            "id": "GooglePaLM_0-input-temperature-number"
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "description": "Maximum number of tokens to generate in the completion.",
            "id": "GooglePaLM_0-input-maxOutputTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "description": "Top-p changes how the model selects tokens for output.\nTokens are selected from most probable to least until the sum of their probabilities equals the top-p value.\nFor example, if tokens A, B, and C have a probability of .3, .2, and .1 and the top-p value is .5, then the model will select either A or B as the next token (using temperature).",
            "id": "GooglePaLM_0-input-topP-number"
          },
          {
            "label": "Top-k",
            "name": "topK",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "description": "Top-k changes how the model selects tokens for output.\nA top-k of 1 means the selected token is the most probable among all tokens in the model vocabulary (also called greedy decoding), while a top-k of 3 means that the next token is selected from among the 3 most probable tokens (using temperature).",
            "id": "GooglePaLM_0-input-topK-number"
          },
          {
            "label": "Stop Sequences",
            "name": "stopSequencesObj",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "GooglePaLM_0-input-stopSequencesObj-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "GooglePaLM_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "models/text-bison-001",
          "temperature": 0.7,
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "stopSequencesObj": ""
        },
        "outputAnchors": [
          {
            "id": "GooglePaLM_0-output-GooglePaLM-GooglePaLM|LLM|BaseLLM|BaseLanguageModel|Runnable",
            "name": "GooglePaLM",
            "label": "GooglePaLM",
            "description": "Wrapper around Google MakerSuite PaLM large language models",
            "type": "GooglePaLM | LLM | BaseLLM | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 574,
      "selected": false,
      "positionAbsolute": {
        "x": -20.952625954836748,
        "y": -138.18774867984288
      },
      "dragging": false
    }
  ],
  "edges": []
}